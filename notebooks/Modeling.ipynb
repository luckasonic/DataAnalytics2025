{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5a70cdd6561898",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:17.985640Z",
     "start_time": "2025-11-19T19:00:17.692593Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Distribution:\n",
      "Churn\n",
      "0    678\n",
      "1    221\n",
      "Name: count, dtype: int64\n",
      "Churn Rate: 0.246\n",
      "\n",
      "Training set: 629 samples\n",
      "Test set: 270 samples\n",
      "Churn rate - Train: 0.246, Test: 0.244\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../data/Churn_Data_Processed.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"Target Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Churn Rate: {y.mean():.3f}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Churn rate - Train: {y_train.mean():.3f}, Test: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579b51033f145980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:18.011103Z",
     "start_time": "2025-11-19T19:00:17.985640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(0.6635021097046413), 1: np.float64(2.029032258064516)}\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights to handle imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(f\"Class weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f220d96524e7be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:18.018426Z",
     "start_time": "2025-11-19T19:00:18.011103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stratified K-Fold for imbalanced data\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452ccc9b2861ca3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:23.929429Z",
     "start_time": "2025-11-19T19:00:18.021011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Best Parameters: {'lasso__C': 1}\n",
      "LASSO Best CV Score (AUC): 0.866963118159159\n"
     ]
    }
   ],
   "source": [
    "# LASSO Logistic Regression Pipeline with class weights\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', LogisticRegression(\n",
    "        penalty='l1', \n",
    "        solver='liblinear', \n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight=class_weight_dict  # Adjusted for imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter grid for LASSO\n",
    "lasso_param_grid = {\n",
    "    'lasso__C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]  # Wider range for fine-tuning\n",
    "}\n",
    "\n",
    "# K-fold Cross-validated grid search\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso_pipeline, \n",
    "    lasso_param_grid, \n",
    "    cv=kfold, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"LASSO Best Parameters:\", lasso_grid.best_params_)\n",
    "print(\"LASSO Best CV Score (AUC):\", lasso_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2a9e52cf1cab4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:24.015226Z",
     "start_time": "2025-11-19T19:00:23.932842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETAILED CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.93      0.83      0.88       204\n",
      "       Churn       0.61      0.82      0.70        66\n",
      "\n",
      "    accuracy                           0.83       270\n",
      "   macro avg       0.77      0.82      0.79       270\n",
      "weighted avg       0.85      0.83      0.83       270\n",
      "\n",
      "\n",
      "==================================================\n",
      "CHURN CLASS (Class 1) PERFORMANCE\n",
      "==================================================\n",
      "Precision: 0.6067\n",
      "Recall:    0.8182\n",
      "F1-Score:  0.6968\n",
      "Support:   66 samples\n",
      "\n",
      "========================================\n",
      "CONFUSION MATRIX\n",
      "========================================\n",
      "[[169  35]\n",
      " [ 12  54]]\n",
      "\n",
      "True Negatives:  169 | False Positives: 35\n",
      "False Negatives: 12 | True Positives:  54\n",
      "\n",
      "Churn Class Metrics (Manual Calculation):\n",
      "Precision: 0.6067\n",
      "Recall:    0.8182\n",
      "F1-Score:  0.6968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Get the best LASSO model\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_lasso.predict(X_test)\n",
    "y_pred_proba = best_lasso.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"=\" * 60)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "# Focus on churn class (class 1) metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_test, y_pred, average=None, labels=[0, 1]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CHURN CLASS (Class 1) PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Precision: {precision[1]:.4f}\")\n",
    "print(f\"Recall:    {recall[1]:.4f}\") \n",
    "print(f\"F1-Score:  {f1[1]:.4f}\")\n",
    "print(f\"Support:   {support[1]} samples\")\n",
    "\n",
    "# Confusion matrix for detailed analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\" * 40)\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negatives:  {cm[0,0]} | False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]} | True Positives:  {cm[1,1]}\")\n",
    "\n",
    "# Calculate additional churn-specific metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "churn_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "churn_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "churn_f1 = 2 * (churn_precision * churn_recall) / (churn_precision + churn_recall) if (churn_precision + churn_recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nChurn Class Metrics (Manual Calculation):\")\n",
    "print(f\"Precision: {churn_precision:.4f}\")\n",
    "print(f\"Recall:    {churn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {churn_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ac6d50ffec6ca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:31.551491Z",
     "start_time": "2025-11-19T19:00:24.015226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/mariailas/Desktop/DataAnalytics2025-main/.venv/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Best Parameters: {'elasticnet__C': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "ElasticNet Best CV Score (AUC): 0.8694845211862876\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Logistic Regression Pipeline with class weights\n",
    "elasticnet_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elasticnet', LogisticRegression(\n",
    "        penalty='elasticnet', \n",
    "        solver='saga', \n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight=class_weight_dict  # Adjusted for imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter grid for ElasticNet\n",
    "elasticnet_param_grid = {\n",
    "    'elasticnet__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "elasticnet_grid = GridSearchCV(\n",
    "    elasticnet_pipeline, \n",
    "    elasticnet_param_grid, \n",
    "    cv=kfold, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "elasticnet_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"ElasticNet Best Parameters:\", elasticnet_grid.best_params_)\n",
    "print(\"ElasticNet Best CV Score (AUC):\", elasticnet_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1741c3050c315d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:31.886461Z",
     "start_time": "2025-11-19T19:00:31.555439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Best Parameters: {'l2__C': 0.1}\n",
      "L2 Best CV Score (AUC): 0.8684557309540152\n"
     ]
    }
   ],
   "source": [
    "# Standard L2 Logistic Regression Pipeline with class weights\n",
    "l2_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('l2', LogisticRegression(\n",
    "        penalty='l2', \n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight=class_weight_dict  # Adjusted for imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Parameter grid for L2\n",
    "l2_param_grid = {\n",
    "    'l2__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "l2_grid = GridSearchCV(\n",
    "    l2_pipeline, \n",
    "    l2_param_grid, \n",
    "    cv=kfold, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "l2_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"L2 Best Parameters:\", l2_grid.best_params_)\n",
    "print(\"L2 Best CV Score (AUC):\", l2_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d100514d1bdcac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:32.410543Z",
     "start_time": "2025-11-19T19:00:31.886461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K-FOLD CROSS-VALIDATION RESULTS (AUC)\n",
      "============================================================\n",
      "LASSO (L1).......... CV AUC: 0.8670 (+/- 0.0257) | Test AUC: 0.8948\n",
      "ElasticNet.......... CV AUC: 0.8695 (+/- 0.0185) | Test AUC: 0.8850\n",
      "Ridge (L2).......... CV AUC: 0.8685 (+/- 0.0186) | Test AUC: 0.8864\n",
      "\n",
      "            CV_Mean_AUC  CV_Std_AUC  Test_AUC\n",
      "ElasticNet     0.869485    0.009239  0.884952\n",
      "Ridge (L2)     0.868456    0.009279  0.886364\n",
      "LASSO (L1)     0.866963    0.012855  0.894831\n"
     ]
    }
   ],
   "source": [
    "# Get best models\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "best_elasticnet = elasticnet_grid.best_estimator_\n",
    "best_l2 = l2_grid.best_estimator_\n",
    "\n",
    "# Detailed CV performance comparison\n",
    "models = {\n",
    "    'LASSO (L1)': best_lasso,\n",
    "    'ElasticNet': best_elasticnet,\n",
    "    'Ridge (L2)': best_l2\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"K-FOLD CROSS-VALIDATION RESULTS (AUC)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cv_results_comparison = {}\n",
    "for name, model in models.items():\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    \n",
    "    # Train the model on full training data for test evaluation\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test performance\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    cv_results_comparison[name] = {\n",
    "        'CV_Mean_AUC': cv_scores.mean(),\n",
    "        'CV_Std_AUC': cv_scores.std(),\n",
    "        'Test_AUC': test_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"{name:.<20} CV AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f}) | Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(cv_results_comparison).T\n",
    "results_df = results_df.sort_values('CV_Mean_AUC', ascending=False)\n",
    "print(\"\\n\" + results_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2dd189e77aa02e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:00:32.487604Z",
     "start_time": "2025-11-19T19:00:32.414736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SELECTED BEST MODEL: ElasticNet\n",
      " CV AUC: 0.8695\n",
      " Test AUC: 0.8850\n",
      "\n",
      " TOP 10 MOST IMPORTANT FEATURES (ElasticNet):\n",
      "============================================================\n",
      "MultipleLines_Yes.......................  REDUCES churn (impact: 0.5541)\n",
      "tenure..................................  REDUCES churn (impact: 0.4678)\n",
      "InternationalPlan.......................  INCREASES churn (impact: 0.4571)\n",
      "AvgCallDurationBin_Medium...............  INCREASES churn (impact: 0.4477)\n",
      "InternetService_Fiber optic.............  INCREASES churn (impact: 0.4361)\n",
      "AvgCallDurationBin_Very Long............  REDUCES churn (impact: 0.4059)\n",
      "AvgCallPerMonth.........................  INCREASES churn (impact: 0.3929)\n",
      "PhoneService_Yes........................  REDUCES churn (impact: 0.3240)\n",
      "Contract_Two year.......................  REDUCES churn (impact: 0.2693)\n",
      "StreamingTV_Yes.........................  INCREASES churn (impact: 0.2488)\n",
      "\n",
      " Optimal threshold for churn (max F1): 0.62\n",
      "Precision at optimal threshold: 0.70\n",
      "Recall at optimal threshold: 0.74\n",
      "F1-score at optimal threshold: 0.72\n",
      "\n",
      "========================================\n",
      "CONFUSION MATRIX AT OPTIMAL THRESHOLD\n",
      "========================================\n",
      "[[183  21]\n",
      " [ 17  49]]\n",
      "\n",
      "True Negatives: 183 | False Positives: 21\n",
      "False Negatives: 17 | True Positives: 49\n",
      "\n",
      "========================================\n",
      "CHURN CLASS (Class 1) PERFORMANCE\n",
      "========================================\n",
      "Precision: 0.7000\n",
      "Recall:    0.7424\n",
      "F1-Score:  0.7206\n",
      "Support:   66 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\n SELECTED BEST MODEL: {best_model_name}\")\n",
    "print(f\" CV AUC: {results_df.loc[best_model_name, 'CV_Mean_AUC']:.4f}\")\n",
    "print(f\" Test AUC: {results_df.loc[best_model_name, 'Test_AUC']:.4f}\")\n",
    "\n",
    "if best_model_name == 'LASSO (L1)':\n",
    "    best_coefs = best_model.named_steps['lasso'].coef_[0]\n",
    "elif best_model_name == 'ElasticNet':\n",
    "    best_coefs = best_model.named_steps['elasticnet'].coef_[0]\n",
    "else:\n",
    "    best_coefs = best_model.named_steps['l2'].coef_[0]\n",
    "\n",
    "final_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': best_coefs,\n",
    "    'importance': np.abs(best_coefs)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n TOP 10 MOST IMPORTANT FEATURES ({best_model_name}):\")\n",
    "print(\"=\"*60)\n",
    "for i, row in final_importance.head(10).iterrows():\n",
    "    direction = \" INCREASES churn\" if row['coefficient'] > 0 else \" REDUCES churn\"\n",
    "    print(f\"{row['feature']:.<40} {direction} (impact: {row['importance']:.4f})\")\n",
    "\n",
    "\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]  # probability of churn\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"\\n Optimal threshold for churn (max F1): {best_threshold:.2f}\")\n",
    "print(f\"Precision at optimal threshold: {precisions[best_idx]:.2f}\")\n",
    "print(f\"Recall at optimal threshold: {recalls[best_idx]:.2f}\")\n",
    "print(f\"F1-score at optimal threshold: {f1_scores[best_idx]:.2f}\")\n",
    "\n",
    "y_pred_new = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_new)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"CONFUSION MATRIX AT OPTIMAL THRESHOLD\")\n",
    "print(\"========================================\")\n",
    "print(conf_matrix)\n",
    "print(f\"\\nTrue Negatives: {tn} | False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn} | True Positives: {tp}\")\n",
    "\n",
    "churn_precision = tp / (tp + fp)\n",
    "churn_recall = tp / (tp + fn)\n",
    "churn_f1 = 2 * (churn_precision * churn_recall) / (churn_precision + churn_recall)\n",
    "\n",
    "print(\"\\n========================================\")\n",
    "print(\"CHURN CLASS (Class 1) PERFORMANCE\")\n",
    "print(\"========================================\")\n",
    "print(f\"Precision: {churn_precision:.4f}\")\n",
    "print(f\"Recall:    {churn_recall:.4f}\")\n",
    "print(f\"F1-Score:  {churn_f1:.4f}\")\n",
    "print(f\"Support:   {tp + fn} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c64870fafc4679",
   "metadata": {},
   "source": [
    "# Save prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de10cbe4d14627da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T19:05:15.910756Z",
     "start_time": "2025-11-19T19:05:15.894339Z"
    }
   },
   "outputs": [],
   "source": [
    "test_results = X_test.copy()\n",
    "test_results['Actual_Churn'] = y_test\n",
    "test_results['Predicted_Churn'] = y_pred_new\n",
    "test_results['Predicted_Probability'] = y_probs\n",
    "test_results.to_csv('../data/Churn_Test_Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb5eff7539e153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
